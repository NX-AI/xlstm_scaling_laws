import pandas as pd

from .common import create_iso_flop_train_len_df

isoflop_counts_selected = [
    6e18,  # 160M, 400M
    1e19,
    3e19,  # 160M, 400M, 1.4B
    1e20,  # (160M), 400M, 830M, 1.4B
    3e20,
    6e20,  # 400M, 830M,
    3e21,
]

mlstm_model_config_dict = {
    ## ed 512
    "mlstm_80M_1": {
        "num_blocks": 10,
        "embedding_dim": 512,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 16,
        "num_nodes": 1,
        "learning_rate": 0.003,
    },
    "mlstm_80M_2": {
        "num_blocks": 12,
        "embedding_dim": 512,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 16,
        "num_nodes": 1,
        "learning_rate": 0.003,
    },
    "mlstm_80M_3": {
        "num_blocks": 14,
        "embedding_dim": 512,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 16,
        "num_nodes": 1,
        "learning_rate": 0.003,
    },
    "mlstm_80M_4": {
        "num_blocks": 16,
        "embedding_dim": 512,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 16,
        "num_nodes": 1,
        "learning_rate": 0.003,
    },
    ## ed 640
    "mlstm_100M_1": {
        "num_blocks": 10,
        "embedding_dim": 640,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 16,
        "num_nodes": 1,
        "learning_rate": 0.003,
    },
    "mlstm_100M_2": {
        "num_blocks": 12,
        "embedding_dim": 640,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 16,
        "num_nodes": 1,
        "learning_rate": 0.003,
    },
    "mlstm_100M_3": {
        "num_blocks": 14,
        "embedding_dim": 640,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 16,
        "num_nodes": 1,
        "learning_rate": 0.003,
    },
    "mlstm_100M_4": {
        "num_blocks": 16,
        "embedding_dim": 640,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 16,
        "num_nodes": 1,
        "learning_rate": 0.003,
    },
    ## ed 768
    "mlstm_160M_1": {
        "num_blocks": 12,
        "embedding_dim": 768,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_160M_2": {
        "num_blocks": 15,
        "embedding_dim": 768,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_160M_3": {
        "num_blocks": 18,
        "embedding_dim": 768,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    ## ed_896
    "mlstm_200M_1": {
        "num_blocks": 12,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_200M_2": {
        "num_blocks": 15,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_200M_3": {
        "num_blocks": 18,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_200M_4": {
        "num_blocks": 21,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_200M_5": {
        "num_blocks": 24,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_200M_6": {
        "num_blocks": 27,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    ## ed 1024
    "mlstm_400M_1": {
        "num_blocks": 18,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_400M_2": {
        "num_blocks": 21,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_400M_3": {
        "num_blocks": 24,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_400M_4": {
        "num_blocks": 27,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    "mlstm_400M_5": {
        "num_blocks": 30,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.003,
    },
    ## ed 1152
    "mlstm_500M_1": {
        "num_blocks": 24,
        "embedding_dim": 1152,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_500M_2": {
        "num_blocks": 27,
        "embedding_dim": 1152,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_500M_3": {
        "num_blocks": 30,
        "embedding_dim": 1152,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    ## ed 1280
    "mlstm_600M_1": {
        "num_blocks": 24,
        "embedding_dim": 1280,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_600M_2": {
        "num_blocks": 27,
        "embedding_dim": 1280,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_600M_3": {
        "num_blocks": 30,
        "embedding_dim": 1280,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    ## ed_1408
    "mlstm_700M_1": {
        "num_blocks": 24,
        "embedding_dim": 1408,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_700M_2": {
        "num_blocks": 27,
        "embedding_dim": 1408,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_700M_3": {
        "num_blocks": 30,
        "embedding_dim": 1408,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    ## ed 1536
    "mlstm_830M_1": {
        "num_blocks": 24,
        "embedding_dim": 1536,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_830M_2": {
        "num_blocks": 27,
        "embedding_dim": 1536,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_830M_3": {
        "num_blocks": 30,
        "embedding_dim": 1536,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    ## ed 1792
    "mlstm_1.1B_1": {
        "num_blocks": 24,
        "embedding_dim": 1792,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_1.1B_2": {
        "num_blocks": 27,
        "embedding_dim": 1792,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_1.1B_3": {
        "num_blocks": 30,
        "embedding_dim": 1792,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    ## ed 2048
    "mlstm_1.4B_1": {
        "num_blocks": 24,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_1.4B_2": {
        "num_blocks": 27,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_1.4B_3": {
        "num_blocks": 30,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_1.4B_4": {
        "num_blocks": 33,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    "mlstm_1.4B_5": {
        "num_blocks": 36,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.002,
    },
    ## ed 2304
    "mlstm_1.8B_1": {
        "num_blocks": 24,
        "embedding_dim": 2304,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.001,
    },
    "mlstm_1.8B_2": {
        "num_blocks": 27,
        "embedding_dim": 2304,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.001,
    },
    "mlstm_1.8B_3": {
        "num_blocks": 30,
        "embedding_dim": 2304,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.001,
    },
    "mlstm_1.8B_4": {
        "num_blocks": 33,
        "embedding_dim": 2304,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.001,
    },
    "mlstm_2.7B_1": {
        "num_blocks": 29,
        "embedding_dim": 2560,
        "proj_factor_ffn": 2.667,
        "num_heads": 10,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.0008,
    },
    "mlstm_2.7B_2": {
        "num_blocks": 32,
        "embedding_dim": 2560,
        "proj_factor_ffn": 2.667,
        "num_heads": 10,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.0008,
    },
    "mlstm_2.7B_3": {
        "num_blocks": 35,
        "embedding_dim": 2560,
        "proj_factor_ffn": 2.667,
        "num_heads": 10,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.0008,
    },
    "mlstm_2.7B_4": {
        "num_blocks": 38,
        "embedding_dim": 2560,
        "proj_factor_ffn": 2.667,
        "num_heads": 10,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "batch_size_per_device": 8,
        "num_nodes": 2,
        "learning_rate": 0.0008,
    },
}


def create_train_len_df_mlstm_all(
    context_length: int = 8192,
    global_batch_size_override: int | None = None,
) -> pd.DataFrame:
    return create_iso_flop_train_len_df(
        model_type="mlstm_v1",
        model_config_dict=mlstm_model_config_dict,
        context_length=context_length,
        iso_flop_counts=isoflop_counts_selected,
        global_batch_size_override=global_batch_size_override,
    )
