import pandas as pd

from .common import create_iso_flop_train_len_df

context_length = 8192

isoflop_counts_selected = [
    6e18,  # 160M, 400M
    1e19,
    3e19,  # 160M, 400M, 1.4B
    1e20,  # (160M), 400M, 830M, 1.4B
    6e20,  # 400M, 830M,
    3e21,
]

mlstm_model_config_dict_experiment_round_1 = {
    "mlstm_100M_1": {
        "num_blocks": 10,
        "embedding_dim": 640,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_100M_2": {
        "num_blocks": 13,
        "embedding_dim": 640,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_100M_3": {
        "num_blocks": 16,
        "embedding_dim": 640,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_160M_1": {
        "num_blocks": 12,
        "embedding_dim": 768,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_160M_2": {
        "num_blocks": 15,
        "embedding_dim": 768,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_160M_3": {
        "num_blocks": 18,
        "embedding_dim": 768,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_400M_1": {
        "num_blocks": 24,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_400M_2": {
        "num_blocks": 27,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_400M_3": {
        "num_blocks": 30,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_600M_1": {
        "num_blocks": 24,
        "embedding_dim": 1280,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
    "mlstm_600M_2": {
        "num_blocks": 27,
        "embedding_dim": 1280,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
    "mlstm_600M_3": {
        "num_blocks": 30,
        "embedding_dim": 1280,
        "proj_factor_ffn": 2.667,
        "num_heads": 5,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
    "mlstm_830M_1": {
        "num_blocks": 24,
        "embedding_dim": 1536,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.001,
    },
    "mlstm_830M_2": {
        "num_blocks": 27,
        "embedding_dim": 1536,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.001,
    },
    "mlstm_830M_3": {
        "num_blocks": 30,
        "embedding_dim": 1536,
        "proj_factor_ffn": 2.667,
        "num_heads": 6,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.001,
    },
    "mlstm_1.1B_1": {
        "num_blocks": 24,
        "embedding_dim": 1792,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0009,
    },
    "mlstm_1.1B_2": {
        "num_blocks": 27,
        "embedding_dim": 1792,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0009,
    },
    "mlstm_1.1B_3": {
        "num_blocks": 30,
        "embedding_dim": 1792,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,  # 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0009,
    },
    "mlstm_1.4B_1": {
        "num_blocks": 24,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
    "mlstm_1.4B_2": {
        "num_blocks": 27,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
    "mlstm_1.4B_3": {
        "num_blocks": 30,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
    "mlstm_2.7B_1": {
        "num_blocks": 32,
        "embedding_dim": 2560,
        "proj_factor_ffn": 2.667,
        "num_heads": 10,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0007,
    },
    "mlstm_2.7B_2": {
        "num_blocks": 35,
        "embedding_dim": 2560,
        "proj_factor_ffn": 2.667,
        "num_heads": 10,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0007,
    },
    "mlstm_2.7B_3": {
        "num_blocks": 38,
        "embedding_dim": 2560,
        "proj_factor_ffn": 2.667,
        "num_heads": 10,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0007,
    },
    # "mlstm_2.7B_default": {
    #     "num_blocks": 32,
    #     "embedding_dim": 2560,
    #     "proj_factor_ffn": 2.667,
    #     "num_heads": 5,
    #     "proj_factor_qk": 0.5,
    #     "chunk_size": 64,
    #     "vocab_size": 50304,
    #     "ffn_multiple_of": 64,
    #     "global_batch_size": 512,
    #     "learning_rate": 0.0007,
    # },
    # "mlstm_7B_default": {
    #     "num_blocks": 32,
    #     "embedding_dim": 4096,
    #     "proj_factor_ffn": 2.667,
    #     "num_heads": 8,
    #     "proj_factor_qk": 0.5,
    #     "chunk_size": 64,
    #     "vocab_size": 50304,
    #     "ffn_multiple_of": 64,
    #     "global_batch_size": 512,
    #     "learning_rate": 0.0005,
    # },
    # "mlstm_13B_default": {
    #     "num_blocks": 40,
    #     "embedding_dim": 5120,
    #     "proj_factor_ffn": 2.667,
    #     "num_heads": 10,
    #     "proj_factor_qk": 0.5,
    #     "chunk_size": 64,
    #     "vocab_size": 50304,
    #     "ffn_multiple_of": 64,
    #     "global_batch_size": 512,
    #     "learning_rate": 0.0004,
    # },
}


mlstm_model_config_dict_experiment_round_2 = {
    ## ed_896
    "mlstm_200M_1": {
        "num_blocks": 12,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_200M_2": {
        "num_blocks": 15,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_200M_3": {
        "num_blocks": 18,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_200M_4": {
        "num_blocks": 21,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_200M_5": {
        "num_blocks": 24,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    ## ed_1152
    "mlstm_500M_1": {
        "num_blocks": 24,
        "embedding_dim": 1152,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
    "mlstm_500M_2": {
        "num_blocks": 27,
        "embedding_dim": 1152,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
    "mlstm_500M_3": {
        "num_blocks": 30,
        "embedding_dim": 1152,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
    ## ed_1408
    "mlstm_700M_1": {
        "num_blocks": 24,
        "embedding_dim": 1408,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
    "mlstm_700M_2": {
        "num_blocks": 27,
        "embedding_dim": 1408,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
    "mlstm_700M_3": {
        "num_blocks": 30,
        "embedding_dim": 1408,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.002,
    },
}

mlstm_model_config_dict_experiment_round_3 = {
    "mlstm_200M_6": {
        "num_blocks": 27,
        "embedding_dim": 896,
        "proj_factor_ffn": 2.667,
        "num_heads": 7,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_400M_4": {
        "num_blocks": 21,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_400M_5": {
        "num_blocks": 18,
        "embedding_dim": 1024,
        "proj_factor_ffn": 2.667,
        "num_heads": 4,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 128,
        "learning_rate": 0.003,
    },
    "mlstm_1.4B_4": {
        "num_blocks": 33,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
    "mlstm_1.4B_5": {
        "num_blocks": 36,
        "embedding_dim": 2048,
        "proj_factor_ffn": 2.667,
        "num_heads": 8,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
    "mlstm_1.8B_1": {
        "num_blocks": 24,
        "embedding_dim": 2304,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
    "mlstm_1.8B_2": {
        "num_blocks": 27,
        "embedding_dim": 2304,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
    "mlstm_1.8B_3": {
        "num_blocks": 30,
        "embedding_dim": 2304,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
    "mlstm_1.8B_4": {
        "num_blocks": 33,
        "embedding_dim": 2304,
        "proj_factor_ffn": 2.667,
        "num_heads": 9,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 256,
        "learning_rate": 0.0008,
    },
}

mlstm_model_config_dict_experiment_round_6 = {
    "mlstm_3.1B_1": {
        "num_blocks": 30,
        "embedding_dim": 2816,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.002,
    },
    "mlstm_3.1B_2": {
        "num_blocks": 32,
        "embedding_dim": 2816,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.002,
    },
    "mlstm_3.1B_3": {
        "num_blocks": 34,
        "embedding_dim": 2816,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.002,
    },
    "mlstm_3.1B_4": {
        "num_blocks": 36,
        "embedding_dim": 2816,
        "proj_factor_ffn": 2.667,
        "num_heads": 11,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.002,
    },
    "mlstm_3.7B_1": {
        "num_blocks": 30,
        "embedding_dim": 3072,
        "proj_factor_ffn": 2.667,
        "num_heads": 12,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.002,
    },
    "mlstm_3.7B_2": {
        "num_blocks": 32,
        "embedding_dim": 3072,
        "proj_factor_ffn": 2.667,
        "num_heads": 12,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.002,
    },
    "mlstm_3.7B_3": {
        "num_blocks": 34,
        "embedding_dim": 3072,
        "proj_factor_ffn": 2.667,
        "num_heads": 12,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.002,
    },
    "mlstm_3.7B_4": {
        "num_blocks": 36,
        "embedding_dim": 3072,
        "proj_factor_ffn": 2.667,
        "num_heads": 12,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.002,
    },
}

mlstm_model_config_dict_experiment_round_8 = {
    "mlstm_4.5B_1": {
        "num_blocks": 32,
        "embedding_dim": 3328,
        "proj_factor_ffn": 2.667,
        "num_heads": 13,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
    "mlstm_4.5B_2": {
        "num_blocks": 28,
        "embedding_dim": 3328,
        "proj_factor_ffn": 2.667,
        "num_heads": 13,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
    "mlstm_4.5B_3": {
        "num_blocks": 36,
        "embedding_dim": 3328,
        "proj_factor_ffn": 2.667,
        "num_heads": 13,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
    "mlstm_5.5B_1": {
        "num_blocks": 32,
        "embedding_dim": 3584,
        "proj_factor_ffn": 2.667,
        "num_heads": 14,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
    "mlstm_5.5B_2": {
        "num_blocks": 28,
        "embedding_dim": 3584,
        "proj_factor_ffn": 2.667,
        "num_heads": 14,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
    "mlstm_5.5B_3": {
        "num_blocks": 36,
        "embedding_dim": 3584,
        "proj_factor_ffn": 2.667,
        "num_heads": 14,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
    "mlstm_7B_1": {
        "num_blocks": 32,
        "embedding_dim": 4096,
        "proj_factor_ffn": 2.667,
        "num_heads": 16,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
    "mlstm_7B_2": {
        "num_blocks": 28,
        "embedding_dim": 4096,
        "proj_factor_ffn": 2.667,
        "num_heads": 16,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
    "mlstm_7B_3": {
        "num_blocks": 30,
        "embedding_dim": 4096,
        "proj_factor_ffn": 2.667,
        "num_heads": 16,
        "proj_factor_qk": 0.5,
        "chunk_size": 64,
        "vocab_size": 50304,
        "ffn_multiple_of": 64,
        "global_batch_size": 512,
        "learning_rate": 0.0005,
    },
}

# this is the overall model size dict for all experiments
mlstm_model_config_dict = {
    **mlstm_model_config_dict_experiment_round_1,
    **mlstm_model_config_dict_experiment_round_2,
    **mlstm_model_config_dict_experiment_round_3,
    **mlstm_model_config_dict_experiment_round_6,
    **mlstm_model_config_dict_experiment_round_8,
}


def create_train_len_df_mlstm_experiment_round_1() -> pd.DataFrame:
    return create_iso_flop_train_len_df(
        model_type="mlstm_v1",
        model_config_dict=mlstm_model_config_dict_experiment_round_1,
        context_length=context_length,
        iso_flop_counts=isoflop_counts_selected,
    )


def create_train_len_df_mlstm_experiment_round_2() -> pd.DataFrame:
    return create_iso_flop_train_len_df(
        model_type="mlstm_v1",
        model_config_dict=mlstm_model_config_dict_experiment_round_2,
        context_length=context_length,
        iso_flop_counts=isoflop_counts_selected,
    )


def create_train_len_df_mlstm_experiment_round_3() -> pd.DataFrame:
    return create_iso_flop_train_len_df(
        model_type="mlstm_v1",
        model_config_dict=mlstm_model_config_dict_experiment_round_3,
        context_length=context_length,
        iso_flop_counts=isoflop_counts_selected,
    )


def create_train_len_df_mlstm_all_experiments(
    global_batch_size_override: int | None = None,
) -> pd.DataFrame:
    return create_iso_flop_train_len_df(
        model_type="mlstm_v1",
        model_config_dict=mlstm_model_config_dict,
        context_length=context_length,
        iso_flop_counts=isoflop_counts_selected,
        global_batch_size_override=global_batch_size_override,
    )
